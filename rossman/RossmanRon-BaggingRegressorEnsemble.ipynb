{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import *\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.svm import NuSVR\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtypes = {\"Date\": datetime, \"StateHoliday\": np.dtype(str), \"SchoolHoliday\": np.dtype(int)}\n",
    "\n",
    "# The read_csv returns an error when reading the stores data because of missing values but\n",
    "# works when I don't specify the dtypes\n",
    "store_dtypes = {\"CompetitionSinceYear\": np.dtype(int), \"CompetitionSinceMonth\": np.dtype(int), \n",
    "                \"Promo2SinceYear\": np.dtype(int), \"Promo2SinceWeek\": np.dtype(int)}\n",
    "data = pd.read_csv('data/train.csv', dtype=dtypes, parse_dates=[2])\n",
    "stores = pd.read_csv('data/store.csv')\n",
    "\n",
    "test = pd.read_csv('data/test.csv', dtype=dtypes, parse_dates=[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1017209 entries, 0 to 1017208\n",
      "Data columns (total 9 columns):\n",
      "Store            1017209 non-null int64\n",
      "DayOfWeek        1017209 non-null int64\n",
      "Date             1017209 non-null datetime64[ns]\n",
      "Sales            1017209 non-null int64\n",
      "Customers        1017209 non-null int64\n",
      "Open             1017209 non-null int64\n",
      "Promo            1017209 non-null int64\n",
      "StateHoliday     1017209 non-null object\n",
      "SchoolHoliday    1017209 non-null int64\n",
      "dtypes: datetime64[ns](1), int64(7), object(1)\n",
      "memory usage: 77.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove rows with sales of 0\n",
    "data = data[data.Sales > 0]\n",
    "\n",
    "# extract sales to separate Series\n",
    "sales = data[['Store','Sales']]\n",
    "\n",
    "# remove Sales and Customers columns\n",
    "data.drop(['Sales','Customers'], axis=1, inplace=True)\n",
    "\n",
    "# check Open column and set to open if NaN\n",
    "data.Open.fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', 'a', 'b', 'c'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all the values for StateHoliday\n",
    "pd.unique(data.StateHoliday.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all the values for SchoolHoliday\n",
    "pd.unique(data.SchoolHoliday.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# recode StateHoliday as dummy variable\n",
    "def stateHoliday_asDummy(df):\n",
    "    sh = pd.get_dummies(df['StateHoliday'])\n",
    "\n",
    "    sh.rename(columns={'0':'noHoliday','a':'PublicHoliday'}, inplace=True)\n",
    "    sh[['noHoliday','PublicHoliday']] = sh[['noHoliday','PublicHoliday']].astype(int)\n",
    "    try:\n",
    "        sh.rename(columns={'b':'EasterHoliday','c':'XmasHoliday'}, inplace=True)\n",
    "        sh[['EasterHoliday','XmasHoliday']] = sh[['EasterHoliday','XmasHoliday']].astype(int)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    df = pd.concat([df,sh], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# recode SchoolHoliday as binary instead of categorical\n",
    "def schoolHoliday_asDummy(df):\n",
    "    df.SchoolHoliday = df.SchoolHoliday.apply(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recodeCategorical_asInt(df, fn, newfn):\n",
    "    df[newfn] = pd.Categorical.from_array(df[fn]).codes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dummy variable approach\n",
    "data = stateHoliday_asDummy(data)\n",
    "data = schoolHoliday_asDummy(data)\n",
    "\n",
    "# Categorical variable approach\n",
    "data = recodeCategorical_asInt(data, 'SchoolHoliday', 'SchoolHolidayVal')\n",
    "data = recodeCategorical_asInt(data, 'StateHoliday', 'StateHolidayVal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find NaN values in test data\n",
    "#test.isnull().sum().sum()  # indicates 11 missing values\n",
    "# test.Open.isnull().sum()  # they are all in the Open column\n",
    "test.Open.fillna(1, inplace=True)\n",
    "test.Open = test.Open.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = stateHoliday_asDummy(test)\n",
    "test = schoolHoliday_asDummy(test)\n",
    "\n",
    "test = recodeCategorical_asInt(test, 'StateHoliday', 'StateHolidayVal')\n",
    "test = recodeCategorical_asInt(test, 'SchoolHoliday', 'SchoolHolidayVal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# recode StoreType and Assortment as dummy variables\n",
    "def storeType_asDummy(df):\n",
    "    st = pd.get_dummies(df['StoreType'])    \n",
    "    st.rename(columns={'a':'StoreTypeA','b':'StoreTypeB','c':'StoreTypeC','d':'StoreTypeD'}, inplace=True)\n",
    "    df = pd.concat([df,st], axis=1)    \n",
    "    df[['StoreTypeA','StoreTypeB','StoreTypeC','StoreTypeD']] = df[['StoreTypeA','StoreTypeB','StoreTypeC','StoreTypeD']].astype(int)\n",
    "    return df\n",
    "    \n",
    "def assortment_asDummy(df):\n",
    "    ass = pd.get_dummies(df['Assortment'])\n",
    "    ass.rename(columns={'a':'BasicAssortment','b':'ExtraAssortment','c':'ExtendedAssortment'}, inplace=True)\n",
    "    df = pd.concat([df,ass], axis=1)\n",
    "    df[['BasicAssortment','ExtraAssortment','ExtendedAssortment']] = df[['BasicAssortment','ExtraAssortment','ExtendedAssortment']].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert PromoInterval to dummy variable\n",
    "def promoInterval_asDummy(df):\n",
    "    pi = pd.get_dummies(df['PromoInterval'])\n",
    "    pi.rename(columns={'Feb,May,Aug,Nov':'PromoIntFebMayAugNov','Jan,Apr,Jul,Oct':'PromoIntJanAprJulOct',\n",
    "                       'Mar,Jun,Sept,Dec':'PromoIntMarJunSeptDec','None':'PromoIntNone'}, inplace=True)\n",
    "    df = pd.concat([df,pi], axis=1)\n",
    "    df[['PromoIntFebMayAugNov','PromoIntJanAprJulOct','PromoIntMarJunSeptDec','PromoIntNone']] = \\\n",
    "        df[['PromoIntFebMayAugNov','PromoIntJanAprJulOct','PromoIntMarJunSeptDec','PromoIntNone']].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean up NaN values\n",
    "\n",
    "# Set competition distance to 0 if NaN\n",
    "stores.CompetitionDistance.fillna(0, inplace=True)\n",
    "\n",
    "# Set CompetitionOpenSince values to 0 if NaN\n",
    "stores.CompetitionOpenSinceMonth.fillna(0, inplace=True)\n",
    "stores.CompetitionOpenSinceYear.fillna(0, inplace=True)\n",
    "\n",
    "# Set Promo2Since values to 0 if NaN\n",
    "stores.Promo2SinceWeek.fillna(0, inplace=True)\n",
    "stores.Promo2SinceYear.fillna(0, inplace=True)\n",
    "\n",
    "# Set PromoInterval value to the string 'None' if NaN\n",
    "stores.PromoInterval.fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dummy variables\n",
    "stores = storeType_asDummy(stores)\n",
    "stores = assortment_asDummy(stores)\n",
    "stores = promoInterval_asDummy(stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Categorical variables\n",
    "stores = recodeCategorical_asInt(stores, 'StoreType', 'StoreTypeVal')\n",
    "stores = recodeCategorical_asInt(stores, 'Assortment', 'AssortmentVal')\n",
    "stores = recodeCategorical_asInt(stores, 'PromoInterval', 'PromoIntervalVal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform a left outer join of the data and stores dataframes\n",
    "all_data = pd.merge(data, stores, on='Store', how='left')\n",
    "\n",
    "# same for the test data\n",
    "all_test = pd.merge(test, stores, on='Store', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41088 entries, 0 to 41087\n",
      "Data columns (total 35 columns):\n",
      "Id                           41088 non-null int64\n",
      "Store                        41088 non-null int64\n",
      "DayOfWeek                    41088 non-null int64\n",
      "Date                         41088 non-null datetime64[ns]\n",
      "Open                         41088 non-null int64\n",
      "Promo                        41088 non-null int64\n",
      "StateHoliday                 41088 non-null object\n",
      "SchoolHoliday                41088 non-null int64\n",
      "noHoliday                    41088 non-null int64\n",
      "PublicHoliday                41088 non-null int64\n",
      "StateHolidayVal              41088 non-null int8\n",
      "SchoolHolidayVal             41088 non-null int8\n",
      "StoreType                    41088 non-null object\n",
      "Assortment                   41088 non-null object\n",
      "CompetitionDistance          41088 non-null float64\n",
      "CompetitionOpenSinceMonth    41088 non-null float64\n",
      "CompetitionOpenSinceYear     41088 non-null float64\n",
      "Promo2                       41088 non-null int64\n",
      "Promo2SinceWeek              41088 non-null float64\n",
      "Promo2SinceYear              41088 non-null float64\n",
      "PromoInterval                41088 non-null object\n",
      "StoreTypeA                   41088 non-null int64\n",
      "StoreTypeB                   41088 non-null int64\n",
      "StoreTypeC                   41088 non-null int64\n",
      "StoreTypeD                   41088 non-null int64\n",
      "BasicAssortment              41088 non-null int64\n",
      "ExtraAssortment              41088 non-null int64\n",
      "ExtendedAssortment           41088 non-null int64\n",
      "PromoIntFebMayAugNov         41088 non-null int64\n",
      "PromoIntJanAprJulOct         41088 non-null int64\n",
      "PromoIntMarJunSeptDec        41088 non-null int64\n",
      "PromoIntNone                 41088 non-null int64\n",
      "StoreTypeVal                 41088 non-null int8\n",
      "AssortmentVal                41088 non-null int8\n",
      "PromoIntervalVal             41088 non-null int8\n",
      "dtypes: datetime64[ns](1), float64(5), int64(20), int8(5), object(4)\n",
      "memory usage: 9.9+ MB\n"
     ]
    }
   ],
   "source": [
    "all_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now that we have the observation date combined with store metadata, we can recompute \n",
    "# the promosince... and competitionsince... year/week values as weeks before observation date\n",
    "\n",
    "# This takes a really long time to execute...\n",
    "\n",
    "def monthsPromo(x):\n",
    "    months = 0\n",
    "    if x.Promo2SinceYear > 0:\n",
    "        d1s = str(int(x.Promo2SinceYear)) + '-' + str(int(x.Promo2SinceWeek))\n",
    "        d1 = datetime.strptime(d1s + '-1', \"%Y-%W-%w\")\n",
    "        months = (x.Date.year - d1.year) * 12 + x.Date.month - d1.month\n",
    "        if months < 0:\n",
    "            months = 0\n",
    "    return months\n",
    "\n",
    "def weeksPromo(x):\n",
    "    weeks = 0\n",
    "    if x.Promo2SinceYear > 0:\n",
    "        d1s = str(int(x.Promo2SinceYear)) + '-' + str(int(x.Promo2SinceWeek))\n",
    "        d1 = datetime.strptime(d1s + '-1', \"%Y-%W-%w\")\n",
    "        m1 = (d1 - timedelta(days=d1.weekday()))\n",
    "        m2 = (x.Date - timedelta(days=x.Date.weekday()))\n",
    "        weeks = (m2 - m1).days / 7\n",
    "        if weeks < 0:\n",
    "            weeks = 0\n",
    "    return weeks\n",
    "\n",
    "def monthsComp(x):\n",
    "    months = 0\n",
    "    if x.CompetitionOpenSinceYear > 0:\n",
    "        d1s = str(int(x.CompetitionOpenSinceYear)) + '-' + str(int(x.CompetitionOpenSinceMonth))\n",
    "        d1 = datetime.strptime(d1s, \"%Y-%m\")\n",
    "        r = relativedelta(x.Date,d1)\n",
    "        months = r.years*12 + r.months\n",
    "        if months < 0:\n",
    "            months = 0\n",
    "    return months\n",
    "\n",
    "def calculateCompPromoFeatures(df):\n",
    "    # Calculate the PromoWeeks and CompetitionMonths as single Series\n",
    "    df['Promo2SinceWeeks'] = df.apply(weeksPromo, axis=1)\n",
    "    df['Promo2SinceMonths'] = df.apply(monthsPromo, axis=1)\n",
    "    df['CompetitionOpenSinceMonths'] = df.apply(monthsComp, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = calculateCompPromoFeatures(all_data)\n",
    "all_test = calculateCompPromoFeatures(all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data['day'] = all_data.Date.dt.day\n",
    "all_data['month'] = all_data.Date.dt.month\n",
    "all_data['year'] = all_data.Date.dt.year\n",
    "\n",
    "all_test['day'] = all_test.Date.dt.day\n",
    "all_test['month'] = all_test.Date.dt.month\n",
    "all_test['year'] = all_test.Date.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate Day of Year from Date\n",
    "#all_data['DayOfYear'] = all_data.Date.dt.dayofyear\n",
    "#all_test['DayOfYear'] = all_test.Date.dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct a feature list for the features we want to include in the models\n",
    "feature_list_1 = ['Store','DayOfWeek','DayOfYear', 'CompetitionDistance', 'CompetitionOpenSinceMonths',\n",
    "                'Promo', 'Promo2', 'Promo2SinceWeeks', 'noHoliday','PublicHoliday','EasterHoliday','XmasHoliday'\n",
    "                'StoreTypeA', 'StoreTypeB', 'StoreTypeC', 'StoreTypeD', 'BasicAssortment', 'ExtraAssortment',\n",
    "                'ExtendedAssortment', 'PromoIntNone', 'PromoIntFebMayAugNov', 'PromoIntJanAprJulOct',\n",
    "                'PromoIntMarJunSeptDec']\n",
    "\n",
    "feature_list_2 = ['Store','DayOfWeek','DayOfYear', 'CompetitionDistance', 'CompetitionOpenSinceMonths',\n",
    "                'Promo', 'Promo2', 'Promo2SinceMonths', 'SchoolHolidayVal','StateHolidayVal',\n",
    "                'StoreTypeVal', 'AssortmentVal', 'PromoIntervalVal']\n",
    "\n",
    "\n",
    "feature_list_3 = ['Store','DayOfWeek','day', 'month', 'year', 'CompetitionDistance', 'CompetitionOpenSinceMonths',\n",
    "                'Promo', 'Promo2', 'Promo2SinceMonths', 'SchoolHolidayVal','StateHolidayVal',\n",
    "                'StoreTypeVal', 'AssortmentVal', 'PromoIntervalVal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdata = all_data[feature_list_3].as_matrix()\n",
    "ptest = all_data[feature_list_3].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(844338, 15)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# turn everything into categorical variables\n",
    "\n",
    "le1 = preprocessing.LabelEncoder()\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "le3 = preprocessing.LabelEncoder()\n",
    "le4 = preprocessing.LabelEncoder()\n",
    "le5 = preprocessing.LabelEncoder()\n",
    "le6 = preprocessing.LabelEncoder()\n",
    "le7 = preprocessing.LabelEncoder()\n",
    "le8 = preprocessing.LabelEncoder()\n",
    "le9 = preprocessing.LabelEncoder()\n",
    "le10 = preprocessing.LabelEncoder()\n",
    "le11 = preprocessing.LabelEncoder()\n",
    "le12 = preprocessing.LabelEncoder()\n",
    "le13 = preprocessing.LabelEncoder()\n",
    "le14 = preprocessing.LabelEncoder()\n",
    "le15 = preprocessing.LabelEncoder()\n",
    "\n",
    "\n",
    "le1.fit([i[0] for i in pdata])\n",
    "le2.fit([i[1] for i in pdata])\n",
    "le3.fit([i[2] for i in pdata])\n",
    "le4.fit([i[3] for i in pdata])\n",
    "le5.fit([i[4] for i in pdata])\n",
    "le6.fit([i[5] for i in pdata])\n",
    "le7.fit([i[6] for i in pdata])\n",
    "le8.fit([i[7] for i in pdata])\n",
    "le9.fit([i[8] for i in pdata])\n",
    "le10.fit([i[9] for i in pdata])\n",
    "le11.fit([i[10] for i in pdata])\n",
    "le12.fit([i[11] for i in pdata])\n",
    "le13.fit([i[12] for i in pdata])\n",
    "le14.fit([i[13] for i in pdata])\n",
    "le15.fit([i[14] for i in pdata])\n",
    "\n",
    "X_cat1 = le1.transform([i[0] for i in pdata])\n",
    "X_cat2 = le2.transform([i[1] for i in pdata])\n",
    "X_cat3 = le3.transform([i[2] for i in pdata])\n",
    "X_cat4 = le4.transform([i[3] for i in pdata])\n",
    "X_cat5 = le5.transform([i[4] for i in pdata])\n",
    "X_cat6 = le6.transform([i[5] for i in pdata])\n",
    "X_cat7 = le7.transform([i[6] for i in pdata])\n",
    "X_cat8 = le8.transform([i[7] for i in pdata])\n",
    "X_cat9 = le9.transform([i[8] for i in pdata])\n",
    "X_cat10 = le10.transform([i[9] for i in pdata])\n",
    "X_cat11 = le11.transform([i[10] for i in pdata])\n",
    "X_cat12 = le12.transform([i[11] for i in pdata])\n",
    "X_cat13 = le13.transform([i[12] for i in pdata])\n",
    "X_cat14 = le14.transform([i[13] for i in pdata])\n",
    "X_cat15 = le15.transform([i[14] for i in pdata])\n",
    "\n",
    "X_cat = [[X_cat1[i],X_cat2[i],X_cat3[i],X_cat4[i],X_cat5[i],\n",
    "          X_cat6[i],X_cat7[i],X_cat8[i],X_cat9[i],X_cat10[i],\n",
    "          X_cat11[i],X_cat12[i],X_cat13[i],X_cat14[i],X_cat15[i]] for i in range(len(X_cat1))]\n",
    "\n",
    "\n",
    "#transform test data\n",
    "test_cat1 = le1.transform([i[0] for i in ptest])\n",
    "test_cat2 = le2.transform([i[1] for i in ptest])\n",
    "test_cat3 = le3.transform([i[2] for i in ptest])\n",
    "test_cat4 = le4.transform([i[3] for i in ptest])\n",
    "test_cat5 = le5.transform([i[4] for i in ptest])\n",
    "test_cat6 = le6.transform([i[5] for i in ptest])\n",
    "test_cat7 = le7.transform([i[6] for i in ptest])\n",
    "test_cat8 = le8.transform([i[7] for i in ptest])\n",
    "test_cat9 = le9.transform([i[8] for i in ptest])\n",
    "test_cat10 = le10.transform([i[9] for i in ptest])\n",
    "test_cat11 = le11.transform([i[10] for i in ptest])\n",
    "test_cat12 = le12.transform([i[11] for i in ptest])\n",
    "test_cat13 = le13.transform([i[12] for i in ptest])\n",
    "test_cat14 = le14.transform([i[13] for i in ptest])\n",
    "test_cat15 = le15.transform([i[14] for i in ptest])\n",
    "\n",
    "test_cat = [[test_cat1[i],test_cat2[i],test_cat3[i],test_cat4[i],test_cat5[i],\n",
    "             test_cat6[i],test_cat7[i],test_cat8[i],test_cat9[i],test_cat10[i],\n",
    "             test_cat11[i],test_cat12[i],test_cat13[i],test_cat14[i],test_cat15[i]] for i in range(len(X_cat1))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create dummy vars\n",
    "enc = preprocessing.OneHotEncoder(sparse=True)\n",
    "enc.fit(X_cat)\n",
    "X = enc.transform(X_cat)\n",
    "Xt = enc.transform(test_cat)\n",
    "\n",
    "Y = sales.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Do some cross val testing\n",
    "kf = KFold(np.shape(X)[0], n_folds=2)\n",
    "i=0\n",
    "rmspe=[]\n",
    "t1=time.time()\n",
    "for train_index, test_index in kf:\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    #Scale Data\n",
    "    #Scale X\n",
    "    scaler = preprocessing.StandardScaler(with_mean=False)\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    #train model\n",
    "    #mod = NuSVR(nu=0.5, C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, tol=0.001, cache_size=200, verbose=False, max_iter=-1)\n",
    "    mod = RandomForestRegressor(n_estimators=50,n_jobs=-1) #very slow, especially on all data\n",
    "    #mod = GradientBoostingRegressor(n_estimators=50)\n",
    "    #mod = linear_model.SGDRegressor()#~500 error requires scaling\n",
    "    #mod = naive_bayes.GaussianNB() #doesn't work with sparse\n",
    "    mod.fit(X_train_scaled,Y_train)\n",
    "    #make predictions\n",
    "    preds = np.exp(mod.predict(X_test_scaled))\n",
    "    Y_test = np.exp(Y_test)\n",
    "    #score\n",
    "    rmspe.append((np.mean(((preds-Y_test)/(Y_test+1))**2))**0.5)\n",
    "    print i+1,rmspe[i]\n",
    "    i=i+1\n",
    "print 'Time =',int(time.time()-t1),'s'\n",
    "print 'RMSPE avg =',np.mean(rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from the xgboost source code it looks like the custom feval function is passed two parameters: y_hat and y\n",
    "# where the y is a DMatrix object and the Y-hat the output of the prediction for that Y value.\n",
    "# The return is supposed to be (in this case, I believe) a string, value tuple\n",
    "# https://github.com/dmlc/xgboost/blob/master/python-package/xgboost/core.py\n",
    "# Also, how to use this function was not very clear but this example gives a clue:\n",
    "# https://github.com/dmlc/xgboost/blob/master/demo/guide-python/cross_validation.py\n",
    "\n",
    "def rmspe(y_hat, dmat):\n",
    "    # we need to reverse the log(Y)\n",
    "    y = np.exp(dmat.get_label())\n",
    "    return \"rmspe\", np.sqrt(np.mean(((np.exp(y_hat)-y)/(y-1))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepDataframe(df, f):\n",
    "    # take the data from the all_data dataframe and sales dataframe\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df, df.Sales, test_size=0.20, random_state=42)\n",
    "    X_train = X_train[f]\n",
    "    X_test  = X_test[f]\n",
    "\n",
    "    # take the log of the Y values\n",
    "    Ylog_train = np.log(Y_train)\n",
    "    Ylog_test  = np.log(Y_test)\n",
    "    \n",
    "    # scale the data\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    scaled_trainX = scaler.transform(X_train)\n",
    "    scaled_testX = scaler.transform(X_test, len(X_test))\n",
    "    \n",
    "    return(scaled_trainX, Ylog_train, scaled_testX, Ylog_test, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# [546]\teval-rmspe:0.443694\ttrain-rmspe:0.472175  (score 0.39930)\n",
    "param_1 = {'max_depth':10, 'objective':'reg:linear', 'silent':1, 'eta': 0.5,\n",
    "         'booster': 'gblinear', 'alpha' : 0.01, 'lambda' : 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until train error hasn't decreased in 150 rounds.\n",
      "[0]\teval-rmse:5.793334\ttrain-rmse:5.793037\n",
      "[1]\teval-rmse:4.061806\ttrain-rmse:4.061370\n",
      "[2]\teval-rmse:2.850458\ttrain-rmse:2.849940\n",
      "[3]\teval-rmse:2.003362\ttrain-rmse:2.002872\n",
      "[4]\teval-rmse:1.413055\ttrain-rmse:1.412534\n",
      "[5]\teval-rmse:1.000253\ttrain-rmse:0.999536\n",
      "[6]\teval-rmse:0.714765\ttrain-rmse:0.713646\n",
      "[7]\teval-rmse:0.512279\ttrain-rmse:0.510537\n",
      "[8]\teval-rmse:0.376222\ttrain-rmse:0.372849\n",
      "[9]\teval-rmse:0.283114\ttrain-rmse:0.276961\n",
      "[10]\teval-rmse:0.223176\ttrain-rmse:0.212552\n",
      "[11]\teval-rmse:0.183050\ttrain-rmse:0.167778\n",
      "[12]\teval-rmse:0.154486\ttrain-rmse:0.135918\n",
      "[13]\teval-rmse:0.139396\ttrain-rmse:0.117448\n",
      "[14]\teval-rmse:0.130775\ttrain-rmse:0.106168\n",
      "[15]\teval-rmse:0.120684\ttrain-rmse:0.094852\n",
      "[16]\teval-rmse:0.116905\ttrain-rmse:0.090088\n",
      "[17]\teval-rmse:0.113727\ttrain-rmse:0.086299\n",
      "[18]\teval-rmse:0.111754\ttrain-rmse:0.083956\n",
      "[19]\teval-rmse:0.110421\ttrain-rmse:0.082393\n",
      "[20]\teval-rmse:0.108835\ttrain-rmse:0.080716\n",
      "[21]\teval-rmse:0.108330\ttrain-rmse:0.079998\n",
      "[22]\teval-rmse:0.107709\ttrain-rmse:0.079293\n",
      "[23]\teval-rmse:0.107446\ttrain-rmse:0.078899\n",
      "[24]\teval-rmse:0.106836\ttrain-rmse:0.078296\n",
      "[25]\teval-rmse:0.106589\ttrain-rmse:0.077897\n",
      "[26]\teval-rmse:0.106380\ttrain-rmse:0.077577\n",
      "[27]\teval-rmse:0.106079\ttrain-rmse:0.077236\n",
      "[28]\teval-rmse:0.105961\ttrain-rmse:0.077031\n",
      "[29]\teval-rmse:0.105884\ttrain-rmse:0.076893\n",
      "[30]\teval-rmse:0.105753\ttrain-rmse:0.076726\n",
      "[31]\teval-rmse:0.105581\ttrain-rmse:0.076515\n",
      "[32]\teval-rmse:0.105520\ttrain-rmse:0.076412\n",
      "[33]\teval-rmse:0.105444\ttrain-rmse:0.076307\n",
      "[34]\teval-rmse:0.105388\ttrain-rmse:0.076204\n",
      "[35]\teval-rmse:0.105247\ttrain-rmse:0.076038\n",
      "[36]\teval-rmse:0.105166\ttrain-rmse:0.075932\n",
      "[37]\teval-rmse:0.105092\ttrain-rmse:0.075832\n",
      "[38]\teval-rmse:0.104986\ttrain-rmse:0.075700\n",
      "[39]\teval-rmse:0.104941\ttrain-rmse:0.075613\n",
      "[40]\teval-rmse:0.104871\ttrain-rmse:0.075502\n",
      "[41]\teval-rmse:0.104799\ttrain-rmse:0.075402\n",
      "[42]\teval-rmse:0.104762\ttrain-rmse:0.075311\n",
      "[43]\teval-rmse:0.104733\ttrain-rmse:0.075238\n",
      "[44]\teval-rmse:0.104691\ttrain-rmse:0.075173\n",
      "[45]\teval-rmse:0.104647\ttrain-rmse:0.075129\n",
      "[46]\teval-rmse:0.104618\ttrain-rmse:0.075060\n",
      "[47]\teval-rmse:0.104589\ttrain-rmse:0.075007\n",
      "[48]\teval-rmse:0.104568\ttrain-rmse:0.074952\n",
      "[49]\teval-rmse:0.104528\ttrain-rmse:0.074897\n",
      "[50]\teval-rmse:0.104484\ttrain-rmse:0.074827\n",
      "[51]\teval-rmse:0.104432\ttrain-rmse:0.074759\n",
      "[52]\teval-rmse:0.104392\ttrain-rmse:0.074694\n",
      "[53]\teval-rmse:0.104349\ttrain-rmse:0.074616\n",
      "[54]\teval-rmse:0.104332\ttrain-rmse:0.074592\n",
      "[55]\teval-rmse:0.104295\ttrain-rmse:0.074530\n",
      "[56]\teval-rmse:0.104266\ttrain-rmse:0.074472\n",
      "[57]\teval-rmse:0.104253\ttrain-rmse:0.074443\n",
      "[58]\teval-rmse:0.104209\ttrain-rmse:0.074376\n",
      "[59]\teval-rmse:0.104190\ttrain-rmse:0.074313\n",
      "[60]\teval-rmse:0.104139\ttrain-rmse:0.074242\n",
      "[61]\teval-rmse:0.104108\ttrain-rmse:0.074190\n",
      "[62]\teval-rmse:0.104076\ttrain-rmse:0.074142\n",
      "[63]\teval-rmse:0.104060\ttrain-rmse:0.074113\n",
      "[64]\teval-rmse:0.104025\ttrain-rmse:0.074069\n",
      "[65]\teval-rmse:0.104005\ttrain-rmse:0.074042\n",
      "[66]\teval-rmse:0.103972\ttrain-rmse:0.073999\n",
      "[67]\teval-rmse:0.103958\ttrain-rmse:0.073959\n",
      "[68]\teval-rmse:0.103918\ttrain-rmse:0.073895\n",
      "[69]\teval-rmse:0.103900\ttrain-rmse:0.073868\n",
      "[70]\teval-rmse:0.103872\ttrain-rmse:0.073816\n",
      "[71]\teval-rmse:0.103859\ttrain-rmse:0.073785\n",
      "[72]\teval-rmse:0.103833\ttrain-rmse:0.073745\n",
      "[73]\teval-rmse:0.103797\ttrain-rmse:0.073694\n",
      "[74]\teval-rmse:0.103781\ttrain-rmse:0.073669\n",
      "[75]\teval-rmse:0.103771\ttrain-rmse:0.073639\n",
      "[76]\teval-rmse:0.103759\ttrain-rmse:0.073611\n",
      "[77]\teval-rmse:0.103735\ttrain-rmse:0.073577\n",
      "[78]\teval-rmse:0.103722\ttrain-rmse:0.073560\n",
      "[79]\teval-rmse:0.103709\ttrain-rmse:0.073530\n",
      "[80]\teval-rmse:0.103686\ttrain-rmse:0.073505\n",
      "[81]\teval-rmse:0.103660\ttrain-rmse:0.073475\n",
      "[82]\teval-rmse:0.103652\ttrain-rmse:0.073466\n",
      "[83]\teval-rmse:0.103647\ttrain-rmse:0.073443\n",
      "[84]\teval-rmse:0.103639\ttrain-rmse:0.073418\n",
      "[85]\teval-rmse:0.103626\ttrain-rmse:0.073396\n",
      "[86]\teval-rmse:0.103613\ttrain-rmse:0.073366\n",
      "[87]\teval-rmse:0.103583\ttrain-rmse:0.073325\n",
      "[88]\teval-rmse:0.103565\ttrain-rmse:0.073296\n",
      "[89]\teval-rmse:0.103555\ttrain-rmse:0.073279\n",
      "[90]\teval-rmse:0.103544\ttrain-rmse:0.073258\n",
      "[91]\teval-rmse:0.103543\ttrain-rmse:0.073243\n",
      "[92]\teval-rmse:0.103521\ttrain-rmse:0.073210\n",
      "[93]\teval-rmse:0.103504\ttrain-rmse:0.073182\n",
      "[94]\teval-rmse:0.103486\ttrain-rmse:0.073155\n",
      "[95]\teval-rmse:0.103479\ttrain-rmse:0.073137\n",
      "[96]\teval-rmse:0.103457\ttrain-rmse:0.073103\n",
      "[97]\teval-rmse:0.103446\ttrain-rmse:0.073071\n",
      "[98]\teval-rmse:0.103437\ttrain-rmse:0.073053\n",
      "[99]\teval-rmse:0.103429\ttrain-rmse:0.073035\n",
      "[100]\teval-rmse:0.103418\ttrain-rmse:0.073014\n",
      "[101]\teval-rmse:0.103409\ttrain-rmse:0.072985\n",
      "[102]\teval-rmse:0.103395\ttrain-rmse:0.072961\n",
      "[103]\teval-rmse:0.103389\ttrain-rmse:0.072946\n",
      "[104]\teval-rmse:0.103375\ttrain-rmse:0.072923\n",
      "[105]\teval-rmse:0.103369\ttrain-rmse:0.072908\n",
      "[106]\teval-rmse:0.103350\ttrain-rmse:0.072886\n",
      "[107]\teval-rmse:0.103338\ttrain-rmse:0.072850\n",
      "[108]\teval-rmse:0.103336\ttrain-rmse:0.072835\n",
      "[109]\teval-rmse:0.103331\ttrain-rmse:0.072823\n",
      "[110]\teval-rmse:0.103323\ttrain-rmse:0.072809\n",
      "[111]\teval-rmse:0.103309\ttrain-rmse:0.072780\n",
      "[112]\teval-rmse:0.103301\ttrain-rmse:0.072765\n",
      "[113]\teval-rmse:0.103296\ttrain-rmse:0.072743\n",
      "[114]\teval-rmse:0.103281\ttrain-rmse:0.072726\n",
      "[115]\teval-rmse:0.103264\ttrain-rmse:0.072700\n",
      "[116]\teval-rmse:0.103258\ttrain-rmse:0.072690\n",
      "[117]\teval-rmse:0.103256\ttrain-rmse:0.072685\n",
      "[118]\teval-rmse:0.103248\ttrain-rmse:0.072662\n",
      "[119]\teval-rmse:0.103247\ttrain-rmse:0.072652\n",
      "[120]\teval-rmse:0.103240\ttrain-rmse:0.072639\n",
      "[121]\teval-rmse:0.103232\ttrain-rmse:0.072623\n",
      "[122]\teval-rmse:0.103220\ttrain-rmse:0.072602\n",
      "[123]\teval-rmse:0.103217\ttrain-rmse:0.072592\n",
      "[124]\teval-rmse:0.103212\ttrain-rmse:0.072585\n",
      "[125]\teval-rmse:0.103208\ttrain-rmse:0.072574\n",
      "[126]\teval-rmse:0.103199\ttrain-rmse:0.072563\n",
      "[127]\teval-rmse:0.103195\ttrain-rmse:0.072549\n",
      "[128]\teval-rmse:0.103193\ttrain-rmse:0.072544\n",
      "[129]\teval-rmse:0.103179\ttrain-rmse:0.072519\n",
      "[130]\teval-rmse:0.103179\ttrain-rmse:0.072510\n",
      "[131]\teval-rmse:0.103170\ttrain-rmse:0.072491\n",
      "[132]\teval-rmse:0.103158\ttrain-rmse:0.072471\n",
      "[133]\teval-rmse:0.103159\ttrain-rmse:0.072451\n",
      "[134]\teval-rmse:0.103150\ttrain-rmse:0.072435\n",
      "[135]\teval-rmse:0.103144\ttrain-rmse:0.072423\n",
      "[136]\teval-rmse:0.103141\ttrain-rmse:0.072413\n",
      "[137]\teval-rmse:0.103141\ttrain-rmse:0.072409\n",
      "[138]\teval-rmse:0.103126\ttrain-rmse:0.072394\n",
      "[139]\teval-rmse:0.103115\ttrain-rmse:0.072382\n",
      "[140]\teval-rmse:0.103108\ttrain-rmse:0.072367\n",
      "[141]\teval-rmse:0.103102\ttrain-rmse:0.072358\n",
      "[142]\teval-rmse:0.103102\ttrain-rmse:0.072351\n",
      "[143]\teval-rmse:0.103100\ttrain-rmse:0.072346\n",
      "[144]\teval-rmse:0.103092\ttrain-rmse:0.072332\n",
      "[145]\teval-rmse:0.103085\ttrain-rmse:0.072322\n",
      "[146]\teval-rmse:0.103078\ttrain-rmse:0.072308\n",
      "[147]\teval-rmse:0.103073\ttrain-rmse:0.072297\n",
      "[148]\teval-rmse:0.103049\ttrain-rmse:0.072255\n",
      "[149]\teval-rmse:0.103041\ttrain-rmse:0.072244\n",
      "[150]\teval-rmse:0.103036\ttrain-rmse:0.072233\n",
      "[151]\teval-rmse:0.103034\ttrain-rmse:0.072226\n",
      "[152]\teval-rmse:0.103032\ttrain-rmse:0.072217\n",
      "[153]\teval-rmse:0.103025\ttrain-rmse:0.072203\n",
      "[154]\teval-rmse:0.103007\ttrain-rmse:0.072172\n",
      "[155]\teval-rmse:0.103003\ttrain-rmse:0.072160\n",
      "[156]\teval-rmse:0.102997\ttrain-rmse:0.072147\n",
      "[157]\teval-rmse:0.102989\ttrain-rmse:0.072133\n",
      "[158]\teval-rmse:0.102985\ttrain-rmse:0.072124\n",
      "[159]\teval-rmse:0.102980\ttrain-rmse:0.072116\n",
      "[160]\teval-rmse:0.102976\ttrain-rmse:0.072102\n",
      "[161]\teval-rmse:0.102971\ttrain-rmse:0.072094\n",
      "[162]\teval-rmse:0.102969\ttrain-rmse:0.072090\n",
      "[163]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[164]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[165]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[166]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[167]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[168]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[169]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[170]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[171]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[172]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[173]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[174]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[175]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[176]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[177]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[178]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[179]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[180]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[181]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[182]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[183]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[184]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[185]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[186]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[187]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[188]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[189]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[190]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[191]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[192]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[193]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[194]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[195]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[196]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[197]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[198]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[199]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[200]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[201]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[202]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[203]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[204]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[205]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[206]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[207]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[208]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[209]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[210]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[211]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[212]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[213]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[214]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[215]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[216]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[217]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[218]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[219]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[220]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[221]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[222]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[223]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[224]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[225]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[226]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[227]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[228]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[229]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[230]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[231]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[232]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[233]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[234]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[235]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[236]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[237]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[238]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[239]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[240]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[241]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[242]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[243]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[244]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[245]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[246]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[247]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[248]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[249]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[250]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[251]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[252]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[253]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[254]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[255]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[256]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[257]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[258]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[259]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[260]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[261]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[262]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[263]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[264]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[265]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[266]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[267]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[268]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[269]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[270]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[271]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[272]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[273]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[274]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[275]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[276]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[277]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[278]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[279]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[280]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[281]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[282]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[283]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[284]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[285]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[286]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[287]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[288]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[289]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[290]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[291]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[292]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[293]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[294]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[295]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[296]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[297]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[298]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[299]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[300]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[301]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[302]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[303]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[304]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[305]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[306]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[307]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[308]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[309]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[310]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[311]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[312]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "[313]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "Stopping. Best iteration:\n",
      "[163]\teval-rmse:0.102954\ttrain-rmse:0.072070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, Ylog, X_test, Ylog_test, scaler = prepDataframe(all_data, feature_list_3)\n",
    "\n",
    "estimators = [(\"Tree\", DecisionTreeRegressor()),\n",
    "              (\"RandomForest\", RandomForestRegressor())]\n",
    "\n",
    "n_estimators = len(estimators)\n",
    "\n",
    "\n",
    "# bagging ensemble regressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = scaler.transform(all_test[feature_list_3])\n",
    "test_preds = np.exp(bst.predict(xgb.DMatrix(test_data)))\n",
    "\n",
    "outF = open('subxgb10-trees.csv','wb')\n",
    "fwriter = csv.writer(outF,delimiter=',')\n",
    "fwriter.writerow(['Id','Sales'])\n",
    "for i in range(len(test_preds)):\n",
    "    fwriter.writerow([i+1,int(test_preds[i])])\n",
    "\n",
    "outF.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
