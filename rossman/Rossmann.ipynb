{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import naive_bayes\n",
    "import xgboost as xgb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday']\n",
      "['Id', 'Store', 'DayOfWeek', 'Date', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday']\n"
     ]
    }
   ],
   "source": [
    "def load(file):\n",
    "    #open file\n",
    "    inF = open(file,'rb')\n",
    "    rdr = csv.reader(inF,delimiter=',')\n",
    "\n",
    "    #read column names\n",
    "    cols = rdr.next()\n",
    "    print cols\n",
    "\n",
    "    #extract data\n",
    "    dat = []\n",
    "    for l in rdr:\n",
    "        dat.append(l)\n",
    "    return dat\n",
    "\n",
    "dat = load('data/train.csv')\n",
    "test = load('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '5', '2015-07-31', '1', '1', '0', '1']\n",
      "['1', '4', '2015-09-17', '1', '1', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "#extract target var\n",
    "Y = np.array([float(i[3]) for i in dat])\n",
    "\n",
    "#drop sales,customers variables as not in test set\n",
    "dat = [dat[i][:3] + dat[i][5:] for i in range(len(dat))]\n",
    "\n",
    "#drop id from test set\n",
    "test = [test[i][1:] for i in range(len(test))]\n",
    "\n",
    "print dat[0]\n",
    "print test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert dates to dt\n",
    "for i in range(len(dat)):\n",
    "    d = datetime.datetime.strptime(dat[i][2],'%Y-%m-%d')\n",
    "    dat[i] = dat[i][:2] + dat[i][3:] + [str(d.year),str(d.month),str(d.day)]\n",
    "\n",
    "for i in range(len(test)):\n",
    "    d = datetime.datetime.strptime(test[i][2],'%Y-%m-%d')\n",
    "    test[i] = test[i][:2] + test[i][3:] + [str(d.year),str(d.month),str(d.day)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '5', '1', '1', '0', '1', '2015', '7', '31']\n",
      "['1', '4', '1', '1', '0', '0', '2015', '9', '17']\n"
     ]
    }
   ],
   "source": [
    "print dat[0]\n",
    "print test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stores  ['1' '10' '100' ..., '997' '998' '999']\n",
      "dow  ['1' '2' '3' '4' '5' '6' '7']\n",
      "Open  ['0' '1']\n",
      "Promo  ['0' '1']\n",
      "StateHoliday  ['0' 'a' 'b' 'c']\n",
      "SchoolHoliday  ['0' '1']\n"
     ]
    }
   ],
   "source": [
    "#encode string to int\n",
    "le1,le2,le3,le4,le5,le6,le7,le8,le9 = preprocessing.LabelEncoder(),preprocessing.LabelEncoder(),preprocessing.LabelEncoder(),preprocessing.LabelEncoder(),preprocessing.LabelEncoder(),preprocessing.LabelEncoder(),preprocessing.LabelEncoder(),preprocessing.LabelEncoder(),preprocessing.LabelEncoder()\n",
    "le1.fit([i[0] for i in dat])\n",
    "le2.fit([i[1] for i in dat])\n",
    "le3.fit([i[2] for i in dat])\n",
    "le4.fit([i[3] for i in dat])\n",
    "le5.fit([i[4] for i in dat])\n",
    "le6.fit([i[5] for i in dat])\n",
    "le7.fit([i[6] for i in dat])\n",
    "le8.fit([i[7] for i in dat])\n",
    "le9.fit([i[8] for i in dat])\n",
    "\n",
    "print 'stores ',le1.classes_\n",
    "print 'dow ',le2.classes_\n",
    "print 'Open ',le3.classes_\n",
    "print 'Promo ',le4.classes_\n",
    "print 'StateHoliday ',le5.classes_\n",
    "print 'SchoolHoliday ',le6.classes_\n",
    "\n",
    "#transform train data\n",
    "X_cat1 = le1.transform([i[0] for i in dat])\n",
    "X_cat2 = le2.transform([i[1] for i in dat])\n",
    "X_cat3 = le3.transform([i[2] for i in dat])\n",
    "X_cat4 = le4.transform([i[3] for i in dat])\n",
    "X_cat5 = le5.transform([i[4] for i in dat])\n",
    "X_cat6 = le6.transform([i[5] for i in dat])\n",
    "X_cat7 = le7.transform([i[6] for i in dat])\n",
    "X_cat8 = le8.transform([i[7] for i in dat])\n",
    "X_cat9 = le9.transform([i[8] for i in dat])\n",
    "X_cat = [[X_cat1[i],X_cat2[i],X_cat3[i],X_cat4[i],X_cat5[i],X_cat6[i],X_cat7[i],X_cat8[i],X_cat9[i]] for i in range(len(X_cat1))]\n",
    "\n",
    "#fix up test data i[2] contains the 'open' variable which in the test set has some unknown values\n",
    "#here we assume if open is unknown then the shop is open\n",
    "for i in test:\n",
    "    if i[2]=='':\n",
    "        i[2]='1'\n",
    "\n",
    "#transform test data\n",
    "test_cat1 = le1.transform([i[0] for i in test])\n",
    "test_cat2 = le2.transform([i[1] for i in test])\n",
    "test_cat3 = le3.transform([i[2] for i in test])\n",
    "test_cat4 = le4.transform([i[3] for i in test])\n",
    "test_cat5 = le5.transform([i[4] for i in test])\n",
    "test_cat6 = le6.transform([i[5] for i in test])\n",
    "test_cat7 = le7.transform([i[6] for i in test])\n",
    "test_cat8 = le8.transform([i[7] for i in test])\n",
    "test_cat9 = le9.transform([i[8] for i in test])\n",
    "test_cat = [[test_cat1[i],test_cat2[i],test_cat3[i],test_cat4[i],test_cat5[i],test_cat6[i],test_cat7[i],test_cat8[i],test_cat9[i]] for i in range(len(test_cat1))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 1, 1, 0, 1, 2, 9, 24]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create dummy vars\n",
    "enc = preprocessing.OneHotEncoder(sparse=True)\n",
    "enc.fit(X_cat)\n",
    "X = enc.transform(X_cat)\n",
    "test = enc.transform(test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(844338, 1178)\n"
     ]
    }
   ],
   "source": [
    "#don't need stores with 0 sales\n",
    "X = X[Y>0]\n",
    "Y = Y[Y>0]\n",
    "print np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5263.   6064.   8314.  13995.   4822.]\n",
      "[ 8.56845649  8.71012493  9.02569612  9.5464554   8.48094406]\n"
     ]
    }
   ],
   "source": [
    "#log transform sales\n",
    "print Y[:5]\n",
    "Y = np.log(Y)\n",
    "print Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<844338x1178 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 7599042 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-aaeb63a72753>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#mod = linear_model.SGDRegressor()#~500 error requires scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#mod = naive_bayes.GaussianNB() #doesn't work with sparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;31m#make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rcordell/Documents/MIDS/W207/W207env/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;31m# Check input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rcordell/Documents/MIDS/W207/W207env/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric)\u001b[0m\n\u001b[1;32m    442\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    443\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     ensure_min_features)\n\u001b[0m\u001b[1;32m    445\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Users/rcordell/Documents/MIDS/W207/W207env/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         array = _ensure_sparse_format(array, accept_sparse, dtype, order,\n\u001b[0;32m--> 334\u001b[0;31m                                       copy, force_all_finite)\n\u001b[0m\u001b[1;32m    335\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rcordell/Documents/MIDS/W207/W207env/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, order, copy, force_all_finite)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \"\"\"\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         raise TypeError('A sparse matrix was passed, but dense '\n\u001b[0m\u001b[1;32m    240\u001b[0m                         \u001b[0;34m'data is required. Use X.toarray() to '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                         'convert to a dense numpy array.')\n",
      "\u001b[0;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "#Do some cross val testing\n",
    "kf = KFold(np.shape(X)[0], n_folds=2)\n",
    "i=0\n",
    "rmspe=[]\n",
    "t1=time.time()\n",
    "for train_index, test_index in kf:\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    #Scale Data\n",
    "    #Scale X\n",
    "    scaler = preprocessing.StandardScaler(with_mean=False)\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    #train model\n",
    "    #mod = RandomForestRegressor(n_estimators=50,n_jobs=-1) #very slow, especially on all data\n",
    "    #mod = GradientBoostingRegressor(n_estimators=50)\n",
    "    #mod = linear_model.SGDRegressor()#~500 error requires scaling\n",
    "    #mod = naive_bayes.GaussianNB() #doesn't work with sparse\n",
    "    mod.fit(X_train_scaled,Y_train)\n",
    "    #make predictions\n",
    "    preds = np.exp(mod.predict(X_test_scaled))\n",
    "    Y_test = np.exp(Y_test)\n",
    "    #score\n",
    "    rmspe.append((np.mean(((preds-Y_test)/(Y_test+1))**2))**0.5)\n",
    "    print i+1,rmspe[i]\n",
    "    i=i+1\n",
    "print 'Time =',int(time.time()-t1),'s'\n",
    "print 'RMSPE avg =',np.mean(rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xgboost(train_data, train_labels, test_data, test_labels):\n",
    "    dtrain = xgb.DMatrix(train_data, label=train_labels)\n",
    "    dtest = xgb.DMatrix(test_data, label=test_labels)\n",
    "    param = {'objective':'reg:linear'}\n",
    "    param['eval_metric']='auc'\n",
    "    evallist = [(dtest,'eval'), (dtrain,'train')]\n",
    "\n",
    "    num_round=10\n",
    "    return xgb.train(param, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1178 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hold back some test data from the train data\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "#Scale Data\n",
    "#Scale X\n",
    "scaler = preprocessing.StandardScaler(with_mean=False)\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "#train model\n",
    "#mod = RandomForestRegressor(n_estimators=50,n_jobs=-1) #very slow, especially on all data\n",
    "#mod = GradientBoostingRegressor(n_estimators=50)\n",
    "#mod = linear_model.SGDRegressor()#~500 error requires scaling\n",
    "#mod = naive_bayes.GaussianNB() #doesn't work with sparse\n",
    "mod = xgboost(X_train, Y_train, X_test, Y_test)\n",
    "mod.fit(X_train_scaled,Y_train)\n",
    "#make predictions\n",
    "preds = np.exp(mod.predict(X_test_scaled))\n",
    "Y_test = np.exp(Y_test)\n",
    "#score\n",
    "rmspe.append((np.mean(((preds-Y_test)/(Y_test+1))**2))**0.5)\n",
    "rmspe[i]\n",
    "\n",
    "print 'Time =',int(time.time()-t1),'s'\n",
    "print 'RMSPE avg =',np.mean(rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_scaled = scaler.transform(test)\n",
    "test_preds = np.exp( mod.predict(test_scaled) )\n",
    "\n",
    "outF = open('sub3.csv','wb')\n",
    "fwriter = csv.writer(outF,delimiter=',')\n",
    "fwriter.writerow(['Id','Sales'])\n",
    "for i in range(len(test_preds)):\n",
    "    fwriter.writerow([i+1,int(test_preds[i])])\n",
    "outF.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
